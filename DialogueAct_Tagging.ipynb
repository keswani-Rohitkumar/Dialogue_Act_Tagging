{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_ZORURKg-fp"
   },
   "source": [
    "# Dialogue Act Tagging\n",
    "\n",
    "Dialogue act (DA) tagging is an important step in the process of developing dialog systems. DA tagging is a problem usually solved by supervised machine learning approaches that all require large amounts of hand labeled data. A wide range of techniques have been investigated for DA tagging. In this lab, we explore two approaches to DA classification. We are using the Switchboard Dialog Act Corpus for training.\n",
    "Corpus can be downloaded from http://compprag.christopherpotts.net/swda.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziKyA9R4gyw9"
   },
   "source": [
    "The downloaded dataset should be kept in a data folder in the same directory as this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jmTpKt_uefe5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehxr2GohfjL7",
    "outputId": "3a9d6efd-cdfd-41a0-bee6-e232d1b4e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "  from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6E8axaw1hAbM"
   },
   "outputs": [],
   "source": [
    "f = glob.glob(\"/content/drive/My Drive/Lab10/swda/sw*/sw*.csv\")\n",
    "frames = []\n",
    "for i in range(0, len(f)):\n",
    "    frames.append(pd.read_csv(f[i]))\n",
    "\n",
    "result = pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7hKGF7EhM4s",
    "outputId": "af9c8c30-cef1-4b8d-d104-875f0e17e51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of converations in the dataset: 223606\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of converations in the dataset:\",len(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ttyB2lQhc7B"
   },
   "source": [
    "The dataset has many different features, we are only using act_tag and text for this training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-jUifIdshhD0"
   },
   "outputs": [],
   "source": [
    "reduced_df = result[['act_tag','text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iPmZvysqg2i"
   },
   "source": [
    "Reduce down the number of tags to 43 - converting the combined tags to their generic classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MQuHm0jPt_lz"
   },
   "outputs": [],
   "source": [
    "# Imported from \"https://github.com/cgpotts/swda\"\n",
    "# Convert the combination tags to the generic 43 tags\n",
    "\n",
    "import re\n",
    "def damsl_act_tag(input):\n",
    "        \"\"\"\n",
    "        Seeks to duplicate the tag simplification described at the\n",
    "        Coders' Manual: http://www.stanford.edu/~jurafsky/ws97/manual.august1.html\n",
    "        \"\"\"\n",
    "        d_tags = []\n",
    "        tags = re.split(r\"\\s*[,;]\\s*\", input)\n",
    "        for tag in tags:\n",
    "            if tag in ('qy^d', 'qw^d', 'b^m'): pass\n",
    "            elif tag == 'nn^e': tag = 'ng'\n",
    "            elif tag == 'ny^e': tag = 'na'\n",
    "            else: \n",
    "                tag = re.sub(r'(.)\\^.*', r'\\1', tag)\n",
    "                tag = re.sub(r'[\\(\\)@*]', '', tag)            \n",
    "                if tag in ('qr', 'qy'):                         tag = 'qy'\n",
    "                elif tag in ('fe', 'ba'):                       tag = 'ba'\n",
    "                elif tag in ('oo', 'co', 'cc'):                 tag = 'oo_co_cc'\n",
    "                elif tag in ('fx', 'sv'):                       tag = 'sv'\n",
    "                elif tag in ('aap', 'am'):                      tag = 'aap_am'\n",
    "                elif tag in ('arp', 'nd'):                      tag = 'arp_nd'\n",
    "                elif tag in ('fo', 'o', 'fw', '\"', 'by', 'bc'): tag = 'fo_o_fw_\"_by_bc'            \n",
    "            d_tags.append(tag)\n",
    "        # Dan J says (p.c.) that it makes sense to take the first;\n",
    "        # there are only a handful of examples with 2 tags here.\n",
    "        return d_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8N_PUCAblq3",
    "outputId": "2eb38f74-b0e9-418a-a13d-b28d82b341a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "reduced_df[\"act_tag\"] = reduced_df[\"act_tag\"].apply(lambda x: damsl_act_tag(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UNy0vvhhqpD"
   },
   "source": [
    "There are 43 tags in this dataset. Some of the tags are Yes-No-Question('qy'), Statement-non-opinion('sd') and Statement-opinion('sv'). Tags information can be found here http://compprag.christopherpotts.net/swda.html#tags. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9biiyP8UiGDe"
   },
   "source": [
    "To get unique tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BrhW8gyLfQQK"
   },
   "outputs": [],
   "source": [
    "unique_tags = set()\n",
    "for tag in reduced_df['act_tag']:\n",
    "    unique_tags.add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LMOX5KwgiPmu"
   },
   "outputs": [],
   "source": [
    "one_hot_encoding_dic = pd.get_dummies(list(unique_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZPHPCxE3iPby"
   },
   "outputs": [],
   "source": [
    "tags_encoding = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    tags_encoding.append(one_hot_encoding_dic[reduced_df['act_tag'].iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVI8QyVzjqWh"
   },
   "source": [
    "The tags are one hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQJTiffPjUtu"
   },
   "source": [
    "To create utterance representations as sequences of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PmkyD1TfjWGO"
   },
   "outputs": [],
   "source": [
    "utterances = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    utterances.append(reduced_df['text'].iloc[i].split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MlD6L6e3jV-7"
   },
   "outputs": [],
   "source": [
    "wordvectors = {}\n",
    "index = 1\n",
    "for u in utterances:\n",
    "    for w in u:\n",
    "        if w not in wordvectors:\n",
    "            wordvectors[w] = index\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e7_cjDHrjV1c"
   },
   "outputs": [],
   "source": [
    "# Max length of 137\n",
    "MAX_LENGTH = len(max(utterances, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LX6DidEvjVWs"
   },
   "outputs": [],
   "source": [
    "utterance_embeddings = []\n",
    "for u in utterances:\n",
    "    utterance_emb = []\n",
    "    for w in u:\n",
    "        utterance_emb.append(wordvectors[w])\n",
    "    utterance_embeddings.append(utterance_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr4iEyNTjmlu"
   },
   "source": [
    "Then we split the dataset into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GiNZ-iI_jnOF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(utterance_embeddings, np.array(tags_encoding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RqMeWe_jron"
   },
   "source": [
    "And pad the utterances with zero to make all utterances of equal length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yqD7DvzRGRY7"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ai9cwv82jufe"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_utterances_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
    "test_utterances_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEjA3ERZ-8Hq"
   },
   "source": [
    "Split Train into Train and Validation - about 10% into validation - In order to validate the model as it is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "517zYSQLXkbn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_input = train_utterances_X[:140000]\n",
    "val_input = train_utterances_X[140000:]\n",
    "\n",
    "train_labels = y_train[:140000]\n",
    "val_labels = y_train[140000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHJbZDtk7N-3"
   },
   "source": [
    "# Model 1 - \n",
    "\n",
    "The first approach we'll try is to treat DA tagging as a standard multi-class text classification task, in the way you've done before with sentiment analysis and other tasks. Each utterance will be treated independently as a text to be classified with its DA tag label. This model has an architecture of:\n",
    "\n",
    "- Embedding  \n",
    "- BLSTM  \n",
    "- Fully Connected Layer\n",
    "- Softmax Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FItlHC1Fjz6y"
   },
   "source": [
    " The model architecture is as follows: Embedding Layer (to generate word embeddings) Next layer Bidirectional LSTM. Feed forward layer with number of neurons = number of tags. Softmax activation to get the probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "M97Sw5iv-lEU"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(wordvectors) # 43,731\n",
    "MAX_LENGTH = len(max(utterances, key=len))\n",
    "EMBED_SIZE = 100 # arbitary\n",
    "HIDDEN_SIZE = len(unique_tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LzhYvpxUjcM5"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCaX-ptaj8G2",
    "outputId": "121f1d14-5f13-48ad-d830-289fd4f2a0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 137, 100)          4373200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 137, 86)           49536     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 86)                44720     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 4,471,197\n",
      "Trainable params: 4,471,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, InputLayer, Bidirectional, TimeDistributed, Activation, Embedding\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#Building the network\n",
    "\n",
    "# Include 2 BLSTM layers, in order to capture both the forward and backward hidden states\n",
    "model = keras.Sequential()\n",
    "#model.add(InputLayer(MAX_LENGTH,))\n",
    "model.add(Embedding(VOCAB_SIZE+1, EMBED_SIZE, input_length = MAX_LENGTH, name = 'embedding_1',\n",
    "                    embeddings_initializer='glorot_uniform'))\n",
    "# Embedding layer\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences= True)))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences= False)))\n",
    "\n",
    "model.add(Dense(HIDDEN_SIZE))\n",
    "model.add(Activation('softmax'))\n",
    "# Bidirectional 1\n",
    "# Bidirectional 2\n",
    "# Dense layer\n",
    "# Activation\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDGZ3fiidYoZ"
   },
   "source": [
    "The above model is build with one embedding layer, two biLSTM layers and one dense layers and softmax activation layer. For multi class classification adam optimizer is used with categorical _crossentropy loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OeiLkgD3Arpl",
    "outputId": "d54ce43e-9481-45e4-c7a5-d1c112367ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "274/274 [==============================] - 64s 104ms/step - loss: 2.2715 - accuracy: 0.4308 - val_loss: 1.3425 - val_accuracy: 0.6114\n",
      "Epoch 2/3\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.2575 - accuracy: 0.6403 - val_loss: 1.1323 - val_accuracy: 0.6746\n",
      "Epoch 3/3\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 1.0396 - accuracy: 0.7026 - val_loss: 1.0427 - val_accuracy: 0.6878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00b01bf890>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model - using validation \n",
    "model.fit(train_input, train_labels,\n",
    "          validation_data = (val_input, val_labels),\n",
    "          epochs = 3,\n",
    "          batch_size = 512,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaWl5pppeUBh"
   },
   "source": [
    "Here the model is trained for 3 epcohs with a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LkONUKQkSrL",
    "outputId": "3db1f3ac-6cc3-44df-fde0-37b3eae8a873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 7s 12ms/step - loss: 1.0402 - accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_utterances_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ab0ZL1dqkTY4",
    "outputId": "cf583812-feec-4523-dea1-de45a8c133b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 69.22650337219238\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl-2FTeCfuuq"
   },
   "source": [
    "Here we are getting the accuracy of 69%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhMViQVSPY1J"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "\n",
    "The overall accuracy is 67%, an effective accuracy for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHwoVCEwjEz7"
   },
   "source": [
    "In addition to overall accuracy, you need to look at the accuracy of some minority classes. Signal-non-understanding ('br') is a good indicator of \"other-repair\" or cases in which the other conversational participant attempts to repair the speaker's error. Summarize/reformulate ('bf') has been used in dialogue summarization. Report the accuracy for these classes and some frequent errors you notice the system makes in predicting them. What do you think the reasons are？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7owA1f27se8"
   },
   "source": [
    "## Minority Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UZ8BwgDxNcIr"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "label_pred = model.predict(test_utterances_X, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUR-bFFLf28Q"
   },
   "source": [
    "Predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAk6Tnzv0XF7",
    "outputId": "a681b2ca-f7f3-4d2e-b330-5c08988bac79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.73706282e-03, 2.15499522e-03, 3.88589664e-03, ...,\n",
       "        1.65701266e-02, 7.09115574e-03, 2.27407411e-01],\n",
       "       [5.23861963e-05, 8.37792351e-04, 1.37821815e-04, ...,\n",
       "        1.15930731e-03, 2.15349472e-04, 8.66751373e-01],\n",
       "       [5.11357968e-04, 1.02662860e-04, 9.16923687e-04, ...,\n",
       "        1.02535174e-04, 5.06404757e-01, 6.92125992e-04],\n",
       "       ...,\n",
       "       [6.92666435e-05, 3.99518409e-04, 1.86881400e-04, ...,\n",
       "        1.88924751e-04, 2.40834153e-04, 1.05741218e-01],\n",
       "       [1.04566815e-03, 2.74903979e-03, 1.91890856e-03, ...,\n",
       "        2.48856694e-01, 5.96832251e-03, 2.80633867e-01],\n",
       "       [2.03770702e-04, 1.15198316e-03, 6.81421894e-04, ...,\n",
       "        7.79251195e-03, 1.09741639e-03, 8.59174609e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5I26g20qQdzF"
   },
   "outputs": [],
   "source": [
    "# Build the confusion matrix off these predictions\n",
    "\n",
    "matrix = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYeRDOKef57C"
   },
   "source": [
    "Building the confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljTxCKxM1NxD",
    "outputId": "30abc0aa-ed47-4528-e94d-e8371ce46893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     1,     4,     6],\n",
       "       [    0,     0,     0, ...,     0,     0,    37],\n",
       "       [    0,     0,     0, ...,     0,     0,     9],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     2,     0,   288],\n",
       "       [    0,     0,     0, ...,     0,  9118,    21],\n",
       "       [    0,     0,     0, ...,     0,     9, 15666]])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muWtF2t0W0zd",
    "outputId": "444cc6d2-8a61-461f-91ca-631cefe2ab1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br accuracy: 0.0\n",
      "bf accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "index_br = list(one_hot_encoding_dic[\"br\"][one_hot_encoding_dic[\"br\"]==1].index)[0]\n",
    "br_accuracy = acc_class[index_br]*100\n",
    "print(\"br accuracy: {}\".format(br_accuracy))\n",
    "\n",
    "index_bf = list(one_hot_encoding_dic[\"bf\"][one_hot_encoding_dic[\"bf\"]==1].index)[0]\n",
    "bf_accuracy = acc_class[index_bf]*100\n",
    "print(\"bf accuracy: {}\".format(bf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ruourSkf__D"
   },
   "source": [
    "Getting the accuracy of the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdnpWLggZ-6z"
   },
   "source": [
    "\n",
    "Due to the reduced lack of training data for the minority classes, these minority classifiers will not be very confident in classification, as they have not been fully optimised. The frequent classifiers will be more optimised and will generate more confident scores for all examples, effectively crowding out the less confident minority classifiers. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ16sE5F7x9e"
   },
   "source": [
    "# Model 2 - Balanced Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKHbOs4WkFaP"
   },
   "source": [
    "\n",
    "One thing we can do to try to improve performance is therefore to balance the data more sensibly. As the dataset is highly imbalanced, we can simply weight the loss function in training, to weight up the minority classes proportionally to their underrepresentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6L4kNdf6kGEa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(tags_encoding, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF1UM-ZMZoa1"
   },
   "source": [
    "## Define & Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIRgRAzOPSAZ",
    "outputId": "3a3ffdbd-b515-479a-ca11-ae893406af7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 137, 100)          4373200   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 137, 86)           49536     \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 86)                44720     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 4,471,197\n",
      "Trainable params: 4,471,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Re-built the model for the balanced training\n",
    "model_balanced = keras.Sequential()\n",
    "model_balanced.add(Embedding(VOCAB_SIZE+1, EMBED_SIZE, input_length = MAX_LENGTH, name = 'embedding_1',\n",
    "                    embeddings_initializer='glorot_uniform'))\n",
    "model_balanced.add(Bidirectional(LSTM(43, return_sequences= True)))\n",
    "model_balanced.add(Bidirectional(LSTM(43, return_sequences= False)))\n",
    "\n",
    "model_balanced.add(Dense(HIDDEN_SIZE))\n",
    "model_balanced.add(Activation('softmax'))\n",
    "model_balanced.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_balanced.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xB2McUREkL4B",
    "outputId": "bd0d8481-307a-4052-ac1e-a42ee11f92dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "274/274 [==============================] - 33s 102ms/step - loss: 3.5196 - accuracy: 0.0532 - val_loss: 2.8657 - val_accuracy: 0.1835\n",
      "Epoch 2/3\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 2.8037 - accuracy: 0.2386 - val_loss: 2.4883 - val_accuracy: 0.3153\n",
      "Epoch 3/3\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 2.2124 - accuracy: 0.3552 - val_loss: 2.2978 - val_accuracy: 0.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00064b6410>"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the balanced network -  takes  time to achieve good accuracy\n",
    "# Train the model - using validation \n",
    "model_balanced.fit(train_input, train_labels,\n",
    "          validation_data = (val_input, val_labels),\n",
    "          epochs = 3,\n",
    "          batch_size = 512,\n",
    "          class_weight = d_class_weights,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kleIpDOqgVTO"
   },
   "source": [
    "Adding class_weight=d_class_weights for a balanced model. This adds a higher penalty for the missclassification of minority classes. This weights the loss function during training. It is used to pay more attention to the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJPjlMclZtw2"
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UMAMGpJRINC",
    "outputId": "843e3514-08af-4b18-d824-ce45959baad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 7s 13ms/step - loss: 2.3029 - accuracy: 0.3414\n"
     ]
    }
   ],
   "source": [
    "# Overall Accuracy\n",
    "score = model_balanced.evaluate(test_utterances_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xzLIkTarjei",
    "outputId": "d7b0c6bd-add6-4772-d786-3b284212b37e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 34.67139005661011\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1Tp9KvVgxZ7"
   },
   "source": [
    "Here we are getting arounf 34% if the accuracy for model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "qkULcz2igEW3"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "label_pred = model_balanced.predict(test_utterances_X, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWKsS_B7VEFI",
    "outputId": "07a0c349-fcd3-4518-c816-f58f35be9bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.10516453e-03, 2.63903290e-02, 5.79506997e-03, ...,\n",
       "        5.25612896e-03, 2.91061867e-03, 1.35663655e-02],\n",
       "       [2.10255588e-04, 6.94551598e-03, 1.71627314e-03, ...,\n",
       "        3.94339347e-03, 4.73002234e-04, 8.10729340e-02],\n",
       "       [6.61013043e-03, 1.87285501e-03, 1.27577735e-02, ...,\n",
       "        3.03130764e-05, 1.66977882e-01, 1.31256631e-04],\n",
       "       ...,\n",
       "       [5.43833303e-04, 1.98218096e-02, 8.89843679e-04, ...,\n",
       "        2.95529906e-02, 1.77580077e-04, 2.07288191e-01],\n",
       "       [1.09919300e-03, 9.79048479e-03, 8.33772356e-05, ...,\n",
       "        6.16566122e-01, 6.51680864e-04, 3.69770452e-02],\n",
       "       [1.92953006e-03, 4.25570495e-02, 3.18737933e-03, ...,\n",
       "        6.11068541e-03, 4.38986666e-04, 4.02017720e-02]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxANZaBwg4Dj"
   },
   "source": [
    "Here we are predciting the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hq7i7giWZ4_l"
   },
   "source": [
    "## Balanced network evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM7VWweco0Et"
   },
   "source": [
    "Report the overall accuracy and the accuracy of  'br' and 'bf'  classes. Suggest other ways to handle imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pxYEZzSUX_2",
    "outputId": "d2846208-d395-4baa-f01a-9bfdfea64381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br accuracy: 43.66197183098591\n",
      "bf accuracy: 18.340611353711793\n"
     ]
    }
   ],
   "source": [
    "matrix_balanced = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "acc_class_balanced = matrix_balanced.diagonal()/matrix_balanced.sum(axis=1)\n",
    "\n",
    "index_br = list(one_hot_encoding_dic[\"br\"][one_hot_encoding_dic[\"br\"]==1].index)[0]\n",
    "br_accuracy = acc_class_balanced[index_br]*100\n",
    "print(\"br accuracy: {}\".format(br_accuracy))\n",
    "\n",
    "index_bf = list(one_hot_encoding_dic[\"bf\"][one_hot_encoding_dic[\"bf\"]==1].index)[0]\n",
    "bf_accuracy = acc_class_balanced[index_bf]*100\n",
    "print(\"bf accuracy: {}\".format(bf_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lvp93uoPKx7V",
    "outputId": "1bbd9514-978c-4a49-d0ce-24d96ae060c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,    0,    0, ...,    2,    1,    0],\n",
       "       [   0,   19,    0, ...,    1,    0,    2],\n",
       "       [   0,    1,   25, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    6,    0, ...,  217,    0,    2],\n",
       "       [  15,    0,    0, ...,    1, 3985,    0],\n",
       "       [  25, 1943,    7, ...,  197,    4, 3632]])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCcCDEEeg-hJ"
   },
   "source": [
    "The overall accuracy of the balanced model is lower than the accuracy of the unbalanced model. But we can see that the individual classes have a much better accuracy in balanced model than the unbalanced model. In balanced model there is a higher penalty when the classification of minority classes were wrong, which results in the low overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi9GyVUvPcrF"
   },
   "source": [
    "\n",
    "\n",
    "### Accuracies\n",
    "\n",
    "\n",
    "\n",
    "### Explanation\n",
    "\n",
    "\n",
    "### Other ways to handle imbalanced classes\n",
    "\n",
    "\n",
    "- Under-sampling: Under-sampling can be used to decrease the instances of majority classes untill it is comparable with the minority class. But as this method removes the data from dataset, some usseful information may be lost.\n",
    "\n",
    "- Over-sampling: Over-sampling can be used to increase the isntances of minority classes on the training set by duplication. The advantage here is that in over-sampling there is no loss of information, whereas there is a chance that model becomes prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fW4g5mQkkaFv"
   },
   "source": [
    "Can we improve things by using context information?  Next we try to build a model which predicts DA tag from the sequence of \n",
    "previous DA tags, plus the utterance representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfrGWuZ6nk4y"
   },
   "source": [
    "# Using Context for Dialog Act Classification\n",
    "\n",
    "The second approach we will try is a hierarchical approach to DA tagging. We expect there is valuable sequential information among the DA tags. So in this section we apply a BiLSTM on top of the utterance CNN representation. The CNN model learns textual information in each utterance for DA classification, acting like the text classifier from Model 1 above. Then we use a bidirectional-LSTM (BLSTM) above that to learn how to use the context before and after the current utterance to improve the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qyPpNaK-2mb"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "This model has an architecture of:\n",
    "\n",
    "- Word Embedding\n",
    "- CNN\n",
    "- Bidirectional LSTM\n",
    "- Fully-Connected output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuJLqgjWqcIf"
   },
   "source": [
    "## CNN\n",
    "\n",
    "\n",
    "This is a classical CNN layer used to convolve over embedings tensor and gether useful information from it. The data is represented by hierarchy of features, which can be modelled using a CNN. We transform/reshape conv output to 2d matrix. Then we pass it to the max pooling layer that applies the max pool operation on windows of different sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "XA5INtFl-fM0"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D#concat\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Model \n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 64\n",
    "drop = 0.2\n",
    "VOCAB_SIZE = len(wordvectors) # 43,731\n",
    "MAX_LENGTH = len(max(utterances, key=len))\n",
    "#MAX_LENGTH = len(max(sentences, key=len))\n",
    "\n",
    "EMBED_SIZE = 100 # arbitary\n",
    "HIDDEN_SIZE = len(unique_tags) \n",
    "\n",
    "# CNN model\n",
    "inputs = Input(shape=(MAX_LENGTH, ), dtype='int32')\n",
    "embedding = Embedding(input_dim=VOCAB_SIZE+1, output_dim=EMBED_SIZE, input_length=MAX_LENGTH)(inputs)\n",
    "reshape = Reshape((MAX_LENGTH, EMBED_SIZE, 1))(embedding)\n",
    "\n",
    "# 3 convolutions\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_0 = BatchNormalization()(conv_0)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_1 = BatchNormalization()(conv_1)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "# maxpool for 3 layers\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[0] + 1, 1), padding='valid')(bn_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[1] + 1, 1), padding='valid')(bn_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[2] + 1, 1), padding='valid')(bn_2)\n",
    "\n",
    "# concatenate tensors\n",
    "merged_1 = concatenate([maxpool_0, maxpool_1, maxpool_2])\n",
    "\n",
    "# flatten concatenated tensors\n",
    "# applying time distributed layer so that cnn output is compatible with BiLSTM input\n",
    "flat = TimeDistributed(Flatten())(merged_1)\n",
    "# dense layer (dense_1)\n",
    "dense_1 = Dense(HIDDEN_SIZE, activation='relu')(flat)\n",
    "# dropout_1\n",
    "dropout_1 = Dropout(drop)(dense_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcOen2c8DVGf"
   },
   "source": [
    "Here I have concatenated the three maxpooling layer and then applied time distributed layer so that the output of the cnn is compatible with BiLSTM input ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nq9RWqNaU4C"
   },
   "source": [
    "If you want CNN layers to interact with the LSTM layer, they need to be distributed across time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDuERMw7-rAV"
   },
   "source": [
    "## BLSTM\n",
    "\n",
    "This is used to create LSTM layers. The data we’re working with has temporal properties which we want to model as well — hence the use of a LSTM. You should create a BiLSTM. Try the output of cnn as the input for blstm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "pFGp2EWI-fM7"
   },
   "outputs": [],
   "source": [
    "biLSTM1 = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences='true'))(dropout_1)\n",
    "# Bidirectional 2\n",
    "biLSTM2 = Bidirectional(LSTM(HIDDEN_SIZE))(biLSTM1)\n",
    "# Dense layer (dense_2)\n",
    "dense_2 = Dense(HIDDEN_SIZE, activation='relu')(biLSTM2)\n",
    "# dropout_2\n",
    "dropout_2 = Dropout(drop)(dense_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPJwLfnJDooA"
   },
   "source": [
    "Here I have create a BiLSTM layer and the output of CNN is the input of the bilstm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wluAkx6AQUb"
   },
   "source": [
    "Concatenate 2 last layers and create the output layer. You need to concatenate the outputs of CNN and LSTM (dropout_1 and dropout_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzrhgkX2-fNE",
    "outputId": "10881b7d-2eca-419b-acae-176b4902cf38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 137)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 137, 100)     4373200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 137, 100, 1)  0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 135, 1, 64)   19264       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 134, 1, 64)   25664       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 133, 1, 64)   32064       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 135, 1, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 134, 1, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 133, 1, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 1, 192)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 1, 192)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 43)        8299        time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 43)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 86)        29928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 86)           44720       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 43)           3741        bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 43)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 43)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 86)           0           flatten_1[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 43)           3741        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 43)           0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,541,389\n",
      "Trainable params: 4,541,005\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 final layers\n",
    "# flatten the output of the CNN + dense + dropout so that it can be concatenated with the output of BiLSTM\n",
    "dropout_flat = Flatten()(dropout_1)\n",
    "# concatenating the output of CNN + dense + dropout with the output of BiLSTM + dense + dropout\n",
    "merged_2 = concatenate([dropout_flat, dropout_2])\n",
    "# merged_2 has the dimension of (None, 86)\n",
    "# adding a dense layer\n",
    "dense_3 = Dense(units=HIDDEN_SIZE, input_shape=(1,))(merged_2)\n",
    "# adding softmax for multiclass classification\n",
    "output = Activation('softmax')(dense_3)\n",
    "\n",
    "optimizer = Adam()\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[output])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Jneg-GD-fNJ",
    "outputId": "1b9b8ae3-033f-49fc-a61f-6c75c7c1f2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "274/274 [==============================] - 58s 188ms/step - loss: 1.6962 - accuracy: 0.5481 - val_loss: 2.5579 - val_accuracy: 0.6378\n",
      "Epoch 2/3\n",
      "274/274 [==============================] - 51s 185ms/step - loss: 0.9087 - accuracy: 0.7277 - val_loss: 1.1647 - val_accuracy: 0.6932\n",
      "Epoch 3/3\n",
      "274/274 [==============================] - 49s 181ms/step - loss: 0.7213 - accuracy: 0.7813 - val_loss: 0.9544 - val_accuracy: 0.7090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f009a65c810>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input,\n",
    "                     train_labels,\n",
    "                     epochs=3,\n",
    "                     batch_size=512,\n",
    "                     validation_data=(val_input, val_labels),verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSMRSX1u-fNO",
    "outputId": "9229bc76-b702-4fe2-e191-8ed801c1b675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 13s 23ms/step - loss: 0.9516 - accuracy: 0.7116\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_utterances_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qFMsXNS-fNS",
    "outputId": "7195cadf-b02f-4941-dc10-10f83d74f66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 71.16203308105469\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K46bQ5ihEbBc"
   },
   "source": [
    "Here for the CNN model we are getting arounf 71% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "lpDCJYF4Yf-s"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "label_cnn = model.predict(test_utterances_X, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-kMUFfzYrPm",
    "outputId": "c7f3cd07-0567-44b8-aee7-f0e4b438bac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.23096542e-03, 5.23082446e-03, 6.40062382e-03, ...,\n",
       "        4.10733372e-03, 1.16247825e-01, 7.28917494e-02],\n",
       "       [1.16260730e-04, 6.15743455e-03, 1.83145439e-05, ...,\n",
       "        1.23911304e-03, 2.97348568e-04, 7.70550787e-01],\n",
       "       [5.68815041e-04, 8.16458414e-05, 8.90097581e-05, ...,\n",
       "        3.98963348e-05, 5.17999470e-01, 3.64799082e-04],\n",
       "       ...,\n",
       "       [6.61671447e-06, 1.04867599e-04, 9.32865532e-07, ...,\n",
       "        1.14181705e-04, 2.97188617e-05, 1.30002528e-01],\n",
       "       [5.05816424e-05, 6.79959776e-04, 1.84000328e-05, ...,\n",
       "        8.57532740e-01, 3.20229854e-04, 4.87545356e-02],\n",
       "       [7.70159604e-05, 2.33231834e-03, 1.53257515e-05, ...,\n",
       "        4.90286329e-04, 5.49002492e-04, 9.07488942e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHbZgxzlYy9b",
    "outputId": "67c3bbc1-1f77-48d5-9e7e-b2989c4308a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br accuracy: 46.478873239436616\n",
      "bf accuracy: 0.8733624454148471\n"
     ]
    }
   ],
   "source": [
    "matrix_1 = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "acc_class_balanced = matrix_1.diagonal()/matrix_1.sum(axis=1)\n",
    "\n",
    "index_br = list(one_hot_encoding_dic[\"br\"][one_hot_encoding_dic[\"br\"]==1].index)[0]\n",
    "br_accuracy = acc_class_balanced[index_br]*100\n",
    "print(\"br accuracy: {}\".format(br_accuracy))\n",
    "\n",
    "index_bf = list(one_hot_encoding_dic[\"bf\"][one_hot_encoding_dic[\"bf\"]==1].index)[0]\n",
    "bf_accuracy = acc_class_balanced[index_bf]*100\n",
    "print(\"bf accuracy: {}\".format(bf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdOxEmChEi4u"
   },
   "source": [
    "Here the accuracy of the minority class br and bf are 46.4% and 0.87%, We can see that the accuracy if the br class has increased and the accuracy if the model bf has decreased compared to the previous model2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKMmrfuisKGJ"
   },
   "source": [
    "Report your overall accuracy and the minority class accuracies. Discuss whether context helped disambiguate and better predict the minority classes ('br' and 'bf'). What are some frequent errors? Show one positive example where adding context changed the prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPogrNTFClZ"
   },
   "source": [
    "IF the model initially predicted the wrong class (BiLSTM) but it later got rectified by CNN + BILSTM then it is considered as a positive change. The code below gets the index of all positive chanegs as well as negative changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "k-ft7M_Yi8B7"
   },
   "outputs": [],
   "source": [
    "index_pos_change = []\n",
    "index_neg_change = []\n",
    "for i in range(len(y_test)):\n",
    "  true_label = y_test[i].argmax(axis=0)\n",
    "  bLISTM_pred = label_pred[i].argmax(axis=0)\n",
    "  cnn_pred = label_cnn[i].argmax(axis=0)\n",
    "  if true_label == bLISTM_pred and true_label != cnn_pred:\n",
    "    index_neg_change.append(i)\n",
    "  elif true_label != bLISTM_pred and true_label == cnn_pred:\n",
    "    index_pos_change.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "VzRoeKWvi-39"
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in wordvectors.items()])\n",
    "# method to decode the sentence from a list of IDs to a string\n",
    "def decode_sentence(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uK0KZR8Fh-h"
   },
   "source": [
    "Now we are printing the values of sentences which changed from biLSTM model to CNN + BiLSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jU-jVFlFBHpa",
    "outputId": "ea3e7900-31b5-432a-f7c2-6b68198f8e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{C So } the advice we gave to them --\n",
      "{C and } # also, {F uh, } they do some of that in Wichita, Kansas. /\n",
      "Oh, yeah.  /\n",
      "Yeah. /\n",
      "-- right now trying to keep abreast of, {F uh, } what's going on in Europe, {D you know, } with all the, U S S R's satellites breaking off, trying to become independent and, {D you know, } European community coming together. /\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for i, val in enumerate(index_pos_change):\n",
    "  index +=1\n",
    "  print(decode_sentence(X_test[val]))\n",
    "  if index ==5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmO6hVsWTaNr"
   },
   "source": [
    "### Minority Classes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "200361138_LAB10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
